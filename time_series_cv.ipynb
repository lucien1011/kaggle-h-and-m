{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c7c32c29-8adf-4760-bcc0-dfcab4dd3e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3049de8b-4917-4d15-b56c-c61dc90ffd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'storage/output/220317_baseline/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da44bde7-8a05-43c8-8bb7-26b860442126",
   "metadata": {},
   "source": [
    "****Prepare Dataset****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7524be3-ff2a-466b-9055-02a631e847ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.06 s, sys: 1.49 s, total: 2.55 s\n",
      "Wall time: 2.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "transactions = cudf.read_csv('storage/transactions_train.csv')\n",
    "articles = cudf.read_csv('storage/articles.csv')\n",
    "customers = cudf.read_csv('storage/customers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2075745c-be75-4d9f-8fc2-182d90f45a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "customers['FN'].fillna(0.,inplace=True)\n",
    "customers['Active'].fillna(0.,inplace=True)\n",
    "customers['club_member_status'].fillna('None',inplace=True)\n",
    "customers['age'] = customers['age'] / 10\n",
    "customers['age'] = customers['age'].astype(int)\n",
    "customers['fashion_news_frequency'] = customers['fashion_news_frequency'].str.lower().fillna('none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a64a19a-96fe-42b4-94e5-843a6864a540",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import train_test_split\n",
    "trn_transactions,test_transactions = train_test_split(transactions,gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "19d082ed-181e-4b7c-a7be-1ff761e4779f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def past_purchase_feature(df,transactions):\n",
    "    transactions['count'] = 1\n",
    "    time_elapsed_last_purchase = transactions['t_dat'].max()-transactions[['customer_id','article_id','t_dat']].groupby(['customer_id','article_id'])['t_dat'].max()\n",
    "    time_elapsed_last_purchase = time_elapsed_last_purchase.dt.days\n",
    "    df = df.merge(time_elapsed_last_purchase,on=['article_id','customer_id'],how='left')\n",
    "    df = df.rename(columns={'t_dat':'time_elapsed_last_purchase'})\n",
    "    df['time_elapsed_last_purchase'].fillna(1e6,inplace=True)\n",
    "    \n",
    "    past_purchase_prob = transactions[['customer_id','article_id','count']].groupby(['customer_id','article_id'])['count'].count().reset_index()\n",
    "    norm = transactions[['customer_id','article_id']].groupby('customer_id').count().reset_index().rename(columns={'article_id':'norm'})\n",
    "    past_purchase_prob = past_purchase_prob.merge(norm,on='customer_id')\n",
    "    past_purchase_prob['count'] = past_purchase_prob['count'] / past_purchase_prob['norm']\n",
    "    past_purchase_prob.drop(columns=['norm'],inplace=True)\n",
    "    df = df.merge(past_purchase_prob,on=['article_id','customer_id'],how='left')\n",
    "    df = df.rename(columns={'count':'past_purchase_prob'})\n",
    "    df['past_purchase_prob'].fillna(0.,inplace=True)\n",
    "    \n",
    "    total_purchase = transactions[['article_id','count']].groupby('article_id')['count'].count().reset_index().rename(columns={'count':'total_purchase'})\n",
    "    norm = transactions['count'].sum()\n",
    "    total_purchase['total_purchase'] = total_purchase['total_purchase'] / norm\n",
    "    df = df.merge(total_purchase,on='article_id',how='left')\n",
    "    df['total_purchase'].fillna(0.,inplace=True)\n",
    "    \n",
    "    number_of_purchase = transactions[['customer_id','count']].groupby('customer_id')['count'].count().reset_index().rename(columns={'count':'number_of_purchase'})\n",
    "    df = df.merge(number_of_purchase,on='customer_id',how='left')\n",
    "    df['number_of_purchase'].fillna(0.,inplace=True)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "def article_feature_prob_vector(df,transactions,articles,article_features,postfix='_prob'):\n",
    "    transactions['count'] = 1\n",
    "    for article_feature in article_features:\n",
    "        transactions = transactions.merge(articles[['article_id',article_feature]],on='article_id',how='left')\n",
    "        norm = transactions.groupby(['customer_id'])['count'].count().reset_index()\n",
    "        norm.rename(columns={'count':'norm'},inplace=True)\n",
    "        count = transactions.groupby(['customer_id',article_feature])['count'].count().reset_index()\n",
    "        count = count.merge(norm,on='customer_id')\n",
    "        count['count'] = count['count'] / count['norm']\n",
    "        count = count.rename(columns={'count':article_feature+postfix})\n",
    "        count = count[['customer_id',article_feature,article_feature+postfix]]\n",
    "        del(norm)\n",
    "        df = df.merge(articles[['article_id',article_feature]],on='article_id',how='left')\n",
    "        df = df.merge(count,on=['customer_id',article_feature],how='left')\n",
    "    return df\n",
    "\n",
    "def customer_feature_prob_vector(df,transactions,customers,customer_features,postfix='_prob'):\n",
    "    transactions['count'] = 1\n",
    "    for customer_feature in customer_features:\n",
    "        transactions = transactions.merge(customers[['customer_id',customer_feature]],on='customer_id',how='left')\n",
    "        norm = transactions.groupby(['article_id'])['count'].count().reset_index()\n",
    "        norm.rename(columns={'count':'norm'},inplace=True)\n",
    "        count = transactions.groupby(['article_id',customer_feature])['count'].count().reset_index()\n",
    "        count = count.merge(norm,on='article_id')\n",
    "        count['count'] = count['count'] / count['norm']\n",
    "        count = count.rename(columns={'count':customer_feature+postfix})\n",
    "        count = count[['article_id',customer_feature,customer_feature+postfix]]\n",
    "        del(norm)\n",
    "        df = df.merge(customers[['customer_id',customer_feature]],on='customer_id',how='left')\n",
    "        df = df.merge(count,on=['article_id',customer_feature],how='left')\n",
    "    return df\n",
    "\n",
    "def construct_feature_df(\n",
    "        df,transactions,\n",
    "        article_features,\n",
    "        articles,\n",
    "        customer_features,\n",
    "        customers,\n",
    "        general_features=['article_id','customer_id'],\n",
    "    ):\n",
    "    df = article_feature_prob_vector(df,transactions,articles,article_features)\n",
    "    df = customer_feature_prob_vector(df,transactions,customers,customer_features)\n",
    "    df = past_purchase_feature(df,transactions)\n",
    "    df = df[general_features+[f for f in df.columns if '_prob' in f]+['time_elapsed_last_purchase','past_purchase_prob','number_of_purchase']]\n",
    "    return df\n",
    "\n",
    "def construct_candidate_dict(transactions_3w):\n",
    "    purchase_dict_3w = {}\n",
    "    for i,x in enumerate(zip(transactions_3w['customer_id'], transactions_3w['article_id'])):\n",
    "        cust_id, art_id = x\n",
    "        if cust_id not in purchase_dict_3w:\n",
    "            purchase_dict_3w[cust_id] = {}\n",
    "        if art_id not in purchase_dict_3w[cust_id]:\n",
    "            purchase_dict_3w[cust_id][art_id] = 0\n",
    "        purchase_dict_3w[cust_id][art_id] += 1\n",
    "    dummy_list_3w = list((transactions_3w['article_id'].value_counts()).index)[:12]\n",
    "    return purchase_dict_3w,dummy_list_3w\n",
    "\n",
    "def construct_candidate_df(test_df,transactions,add_random_samples=False):\n",
    "    \n",
    "    bool_1w = transactions.t_dat>transactions.t_dat.max()-pd.Timedelta(7,unit='day')\n",
    "    bool_2w = (transactions.t_dat>transactions.t_dat.max()-2*pd.Timedelta(7,unit='day'))&(transactions.t_dat<=transactions.t_dat.max()-pd.Timedelta(7,unit='day'))\n",
    "    bool_3w = (transactions.t_dat>transactions.t_dat.max()-3*pd.Timedelta(7,unit='day'))&(transactions.t_dat<=transactions.t_dat.max()-2*pd.Timedelta(7,unit='day'))\n",
    "    \n",
    "    transactions_1w = transactions[bool_1w].to_pandas()\n",
    "    transactions_2w = transactions[bool_2w].to_pandas()\n",
    "    transactions_3w = transactions[bool_3w].to_pandas()\n",
    "    \n",
    "    purchase_dict_1w,dummy_list_1w = construct_candidate_dict(transactions_1w)\n",
    "    purchase_dict_2w,dummy_list_2w = construct_candidate_dict(transactions_2w)\n",
    "    purchase_dict_3w,dummy_list_3w = construct_candidate_dict(transactions_3w)\n",
    "    \n",
    "    pred_df = test_df[['customer_id']]\n",
    "    prediction_list = []\n",
    "    \n",
    "    if add_random_samples:\n",
    "        dummy_pred = transactions['article_id'].sample(frac=1.).to_arrow().to_pylist()[:50]\n",
    "    else:\n",
    "        dummy_pred = list((transactions_1w['article_id'].value_counts()).index)[:12]\n",
    "    \n",
    "    for i, cust_id in enumerate(test_df['customer_id'].values.reshape((-1,))):\n",
    "        s = []\n",
    "        if cust_id in purchase_dict_1w:\n",
    "            l = sorted((purchase_dict_1w[cust_id]).items(), key=lambda x: x[1], reverse=True)\n",
    "            l = [y[0] for y in l]\n",
    "            s += l\n",
    "        if cust_id in purchase_dict_2w:\n",
    "            l = sorted((purchase_dict_2w[cust_id]).items(), key=lambda x: x[1], reverse=True)\n",
    "            l = [y[0] for y in l]\n",
    "            s += l\n",
    "        if cust_id in purchase_dict_3w:\n",
    "            l = sorted((purchase_dict_3w[cust_id]).items(), key=lambda x: x[1], reverse=True)\n",
    "            l = [y[0] for y in l]\n",
    "            s += l\n",
    "        s += dummy_pred\n",
    "        s = list(set(s))\n",
    "        prediction_list.append(s)\n",
    "    pred_df['article_id'] = prediction_list\n",
    "\n",
    "    return pred_df\n",
    "    \n",
    "def construct_val_df(test_df,transactions,article_features,articles,customer_features,customers,how='outer',add_random_samples=False):\n",
    "    pos_df = test_df.groupby('customer_id')['article_id'].unique().to_frame().reset_index().explode('article_id')\n",
    "    pos_df['label'] = 1\n",
    "    test_df = construct_candidate_df(test_df.to_pandas(),transactions,add_random_samples=add_random_samples).explode('article_id').reset_index(drop=True)\n",
    "    test_df = test_df.merge(pos_df.to_pandas(),on=['article_id','customer_id'],how=how)\n",
    "    test_df['label'].fillna(0,inplace=True)\n",
    "    test_df = cudf.from_pandas(test_df)\n",
    "    test_df = construct_feature_df(test_df,transactions,article_features,articles,customer_features,customers,general_features=['article_id','customer_id','label'])\n",
    "    test_df = test_df.fillna(0.)\n",
    "    test_df['article_id'] = test_df['article_id'].astype(int)\n",
    "    test_df = test_df.sort_values(['customer_id','article_id']).reset_index(drop=True)\n",
    "    return test_df\n",
    "\n",
    "def construct_test_df(test_df,transactions,article_features,articles,customer_features,customers,how='outer',add_random_samples=False):\n",
    "    test_df = construct_candidate_df(test_df.to_pandas(),transactions,add_random_samples=add_random_samples).explode('article_id').reset_index(drop=True)\n",
    "    test_df = cudf.from_pandas(test_df)\n",
    "    test_df = construct_feature_df(test_df,transactions,article_features,articles,customer_features,customers,general_features=['article_id','customer_id'])\n",
    "    test_df = test_df.fillna(0.)\n",
    "    test_df['article_id'] = test_df['article_id'].astype(int)\n",
    "    test_df = test_df.sort_values(['customer_id','article_id']).reset_index(drop=True)\n",
    "    return test_df\n",
    "\n",
    "def construct_gt_df(test_transactions):\n",
    "    gt_df = test_transactions.to_pandas().groupby('customer_id')['article_id'].agg(lambda x: x.tolist()).reset_index()\n",
    "    gt_df.columns = ['customer_id','ground_truth']\n",
    "    return gt_df\n",
    "    \n",
    "def construct_dataset(\n",
    "        transactions,\n",
    "        articles,customers,\n",
    "        trn_start_time='2020-08-31',trn_end_time='2020-09-08',\n",
    "        val_start_time='2020-09-08',val_end_time='2020-09-15',\n",
    "        test_start_time='2020-09-08',test_end_time='2020-09-15',\n",
    "        article_features=[\n",
    "            'product_group_name', 'product_type_name', \n",
    "            'graphical_appearance_name', 'perceived_colour_value_name', 'colour_group_code', \n",
    "            'index_name', 'index_group_name', \n",
    "            'section_name', 'department_name',\n",
    "        ],\n",
    "        customer_features=[\n",
    "            'FN','Active','club_member_status','age','fashion_news_frequency',\n",
    "        ],\n",
    "    ):\n",
    "    \n",
    "    trn_start_time = cudf.to_datetime(trn_start_time)\n",
    "    trn_end_time = cudf.to_datetime(trn_end_time)\n",
    "    val_start_time = cudf.to_datetime(val_start_time)\n",
    "    val_end_time = cudf.to_datetime(val_end_time)\n",
    "    test_start_time = cudf.to_datetime(test_start_time)\n",
    "    test_end_time = cudf.to_datetime(test_end_time)\n",
    "    \n",
    "    trn_transactions = transactions[(transactions.t_dat > trn_start_time) & (transactions.t_dat <= trn_end_time)]\n",
    "    val_transactions = transactions[(transactions.t_dat > val_start_time) & (transactions.t_dat <= val_end_time)]\n",
    "    test_transactions = transactions[(transactions.t_dat > test_start_time) & (transactions.t_dat <= test_end_time)]\n",
    "    gt_df = construct_gt_df(test_transactions)\n",
    "    \n",
    "    pos_df = val_transactions[['customer_id','article_id']]\n",
    "    pos_df = construct_feature_df(pos_df,trn_transactions,article_features,articles,customer_features,customers)\n",
    "    pos_df['label'] = 1.\n",
    "    \n",
    "    trn_dfs = [pos_df]\n",
    "    for _ in range(5):\n",
    "        neg_df = val_transactions[['customer_id','article_id']].reset_index().drop(columns=['index'])\n",
    "        neg_df['customer_id'] = neg_df['customer_id'].sample(frac=1.).to_frame().reset_index().drop(columns=['index'])\n",
    "        neg_df = construct_feature_df(neg_df,trn_transactions,article_features,articles,customer_features,customers)\n",
    "        neg_df['label'] = 0.\n",
    "        trn_dfs.append(neg_df)\n",
    "    \n",
    "    trn_df = cudf.concat(trn_dfs)\n",
    "    trn_df = trn_df.fillna(0.)\n",
    "    trn_df = trn_df.sort_values(['customer_id','article_id']).reset_index(drop=True)\n",
    "    \n",
    "    trn_df = trn_df.merge(trn_df.groupby('customer_id').size().to_frame().rename(columns={0:'group_size'}),on='customer_id')\n",
    "    trn_df = trn_df[trn_df['group_size']>5]\n",
    "    \n",
    "    #val_df = construct_test_df(test_transactions,val_transactions,article_features,articles,customer_features,customers,how='left')\n",
    "    test_df = construct_test_df(test_transactions,val_transactions,article_features,articles,customer_features,customers,how='left')\n",
    "    val_df = test_df\n",
    "    \n",
    "    return trn_df.reset_index(drop=True),val_df.reset_index(drop=True),test_df.reset_index(drop=True),gt_df.reset_index(drop=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe0ee52-7410-42b6-a1b6-a8a9e8997897",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for i,(t1,t2,t3,t4) in enumerate([\n",
    "        ('2020-06-01','2020-09-01','2020-09-15','2020-09-22'),\n",
    "        #('2019-06-01','2019-09-01','2019-09-15','2019-09-22'),\n",
    "    ]):\n",
    "    trn_tmp,val_tmp,test_tmp,gt_tmp = construct_dataset(\n",
    "        transactions,\n",
    "        articles,customers,\n",
    "        trn_start_time=t1,trn_end_time=t2,\n",
    "        val_start_time=t2,val_end_time=t3,\n",
    "        test_start_time=t3,test_end_time=t4,\n",
    "    )\n",
    "    dfs.append((trn_tmp,val_tmp,test_tmp,gt_tmp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b899a3aa-e21f-4cf7-99e2-19eae5ec8e5d",
   "metadata": {},
   "source": [
    "****Training****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "500cd90c-02da-41dc-bf44-37170ad8ff60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1e71595c-b057-45cd-9f46-1f024d3ee720",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyperparams = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6d5c33fe-fc07-43d1-920d-1ee33b214740",
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_y_group(data,features,target,only_x=False,verbose=False):\n",
    "    group = data.groupby('customer_id').size().to_frame('size')['size']\n",
    "    data = data.sort_values('customer_id').reset_index()\n",
    "    return data[features],data[target],group\n",
    "\n",
    "def make_prediction(model,test_df,features,label,k=12,group_name='customer_id'):\n",
    "    test_x = test_df[features]\n",
    "    test_pred = model.predict(test_x)\n",
    "    test_x[group_name] = test_df[group_name]\n",
    "    test_x['article_id'] = test_df['article_id']\n",
    "    test_x['prediction'] = test_pred\n",
    "    pred_df = test_x.groupby(group_name) \\\n",
    "                    .apply(lambda x: x.sort_values('prediction',ascending=False)['article_id'].tolist()[:k]) \\\n",
    "                    .reset_index()\n",
    "    pred_df.columns = [group_name,'prediction']\n",
    "    return pred_df\n",
    "\n",
    "def evaluate_score(pred_df,gt_df,k=12,verbose=True,group_name='customer_id'):\n",
    "    from metric import mapk\n",
    "    eval_df = gt_df.merge(pred_df,on=group_name,how='left')\n",
    "    score = mapk(eval_df['ground_truth'].tolist(),eval_df['prediction'].tolist())\n",
    "    if verbose: print('map@'+str(k),score)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "293c58f1-395c-4b1a-a5ca-c42ddf323f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 190 µs, sys: 0 ns, total: 190 µs\n",
      "Wall time: 194 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "features = [c for c in dfs[0][0].columns if c not in ['article_id','customer_id','label','index','group_size']]\n",
    "label = 'label'\n",
    "#trn_x,trn_y,trn_grp = x_y_group(trn_df,features,label)\n",
    "#val_x,val_y,val_grp = x_y_group(val_df,features,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5797d2bc-c834-4787-984c-17b86e0cfda4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kinho.lo/.local/lib/python3.8/site-packages/xgboost/core.py:499: FutureWarning: Pass `group` as keyword args.  Passing these as positional arguments will be considered as error in future releases.\n",
      "  warnings.warn(\n",
      "\n",
      "/scratch/local/21399652/ipykernel_193925/4083372006.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_x[group_name] = test_df[group_name]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.6842720483155474, 'eval_metric': 'map@12', 'gamma': 4.621670610082947, 'learning_rate': 0.7435578636949653, 'max_depth': 13, 'min_child_weight': 1.0, 'n_estimators': 5, 'objective': 'rank:pairwise', 'reg_alpha': 98.0, 'reg_lambda': 0.8902384952199381, 'seed': 0}\n",
      "[0.01753785424273931]                                \n",
      "{'colsample_bytree': 0.877948622970067, 'eval_metric': 'map@12', 'gamma': 3.4873495479305046, 'learning_rate': 0.20337506434029795, 'max_depth': 3, 'min_child_weight': 3.0, 'n_estimators': 5, 'objective': 'rank:pairwise', 'reg_alpha': 133.0, 'reg_lambda': 0.707379435453157, 'seed': 0}\n",
      "[0.017784135119975675]                                                         \n",
      "{'colsample_bytree': 0.8697290277349912, 'eval_metric': 'map@12', 'gamma': 7.833981406446694, 'learning_rate': 0.8974579001210463, 'max_depth': 3, 'min_child_weight': 7.0, 'n_estimators': 5, 'objective': 'rank:pairwise', 'reg_alpha': 47.0, 'reg_lambda': 0.1730920167886617, 'seed': 0}\n",
      "[0.017852925623085318]                                                         \n",
      "{'colsample_bytree': 0.6381603311536519, 'eval_metric': 'map@12', 'gamma': 2.7892188741699977, 'learning_rate': 0.5311525432590475, 'max_depth': 9, 'min_child_weight': 7.0, 'n_estimators': 5, 'objective': 'rank:pairwise', 'reg_alpha': 121.0, 'reg_lambda': 0.7527318956616872, 'seed': 0}\n",
      "[0.017580080546554744]                                                         \n",
      "{'colsample_bytree': 0.80186147510322, 'eval_metric': 'map@12', 'gamma': 3.105133146859485, 'learning_rate': 0.6935952892317561, 'max_depth': 14, 'min_child_weight': 4.0, 'n_estimators': 5, 'objective': 'rank:pairwise', 'reg_alpha': 95.0, 'reg_lambda': 0.7071059022165264, 'seed': 0}\n",
      "[0.01785805568735004]                                                          \n",
      "100%|██████████| 5/5 [02:20<00:00, 28.00s/trial, best loss: 0.98214194431265]  \n",
      "Best hyperparameters:  {'colsample_bytree': 0.80186147510322, 'gamma': 3.105133146859485, 'learning_rate': 0.6935952892317561, 'max_depth': 11, 'min_child_weight': 4.0, 'reg_alpha': 95.0, 'reg_lambda': 0.7071059022165264}\n",
      "CPU times: user 5min 4s, sys: 5.17 s, total: 5min 10s\n",
      "Wall time: 2min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "run_bo = True\n",
    "if run_bo and best_hyperparams is None:\n",
    "    from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "\n",
    "    space = {\n",
    "        'objective': 'rank:pairwise',\n",
    "        'max_depth': hp.choice(\"max_depth\",np.arange(3, 20, dtype=int) ),\n",
    "        'gamma': hp.uniform ('gamma', 1,9),\n",
    "        'learning_rate': hp.uniform('learning_rate',0.1,1.0),\n",
    "        'reg_alpha' : hp.quniform('reg_alpha', 40,180,1),\n",
    "        'reg_lambda' : hp.uniform('reg_lambda', 0,1),\n",
    "        'colsample_bytree' : hp.uniform('colsample_bytree', 0.5,1),\n",
    "        'min_child_weight' : hp.quniform('min_child_weight', 0, 10, 1),\n",
    "        #'n_estimators': hp.choice(\"n_estimators\",np.arange(3, 10, dtype=int) ),\n",
    "        'n_estimators': 5,\n",
    "        'seed': 0,\n",
    "        'eval_metric':'map@12',\n",
    "    }\n",
    "\n",
    "    def time_fold_objective(space):\n",
    "        scores = []\n",
    "        for trn_df,val_df,test_df,gt_df in dfs:\n",
    "            model = xgb.XGBRanker(**space)\n",
    "            trn_x,trn_y,trn_grp = x_y_group(trn_df,features,label)\n",
    "            model.fit(trn_x, trn_y, trn_grp)\n",
    "            pred_df = make_prediction(model,test_df.to_pandas(),features,label,k=12)\n",
    "            score = evaluate_score(pred_df,gt_df,verbose=False)\n",
    "            scores.append(score)\n",
    "        print(space)\n",
    "        print(scores)\n",
    "        return {'loss': 1.-np.mean(scores),'status': STATUS_OK}\n",
    "\n",
    "    trials = Trials()\n",
    "    best_hyperparams = fmin(\n",
    "        fn = time_fold_objective,\n",
    "        space = space,\n",
    "        algo = tpe.suggest,\n",
    "        max_evals = 5,\n",
    "        trials = trials\n",
    "    )\n",
    "    print('Best hyperparameters: ',best_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a7fedc32-9d69-439d-ba2a-c5af0045e1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-map:0.48883\n",
      "[1]\tvalidation_0-map:0.49711\n",
      "[2]\tvalidation_0-map:0.49884\n",
      "[3]\tvalidation_0-map:0.49935\n",
      "[4]\tvalidation_0-map:0.50350\n",
      "CPU times: user 1min 3s, sys: 321 ms, total: 1min 3s\n",
      "Wall time: 16.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRanker(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "          colsample_bynode=1, colsample_bytree=0.80186147510322,\n",
       "          enable_categorical=False, gamma=3.105133146859485, gpu_id=-1,\n",
       "          importance_type=None, interaction_constraints='',\n",
       "          learning_rate=0.6935952892317561, max_delta_step=0, max_depth=11,\n",
       "          min_child_weight=4.0, missing=nan, monotone_constraints='()',\n",
       "          n_estimators=5, n_jobs=4, num_parallel_tree=1, predictor='auto',\n",
       "          random_state=0, reg_alpha=95.0, reg_lambda=0.7071059022165264,\n",
       "          scale_pos_weight=None, seed=0, subsample=1, tree_method='exact',\n",
       "          validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "idx = 0\n",
    "trn_x,trn_y,trn_grp = x_y_group(dfs[idx][0],features,label)\n",
    "model = xgb.XGBRanker(\n",
    "    objective='rank:pairwise',\n",
    "    seed=0,\n",
    "    n_estimators=5,\n",
    "    **best_hyperparams,\n",
    ")\n",
    "model.fit(\n",
    "    trn_x, trn_y, group=trn_grp, verbose=True,\n",
    "    eval_set=[(trn_x,trn_y)], eval_group=[trn_grp],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0a22594d-2bb3-40d3-bfce-49b677f145db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'product_group_name_prob': 28.817983627319336,\n",
       " 'product_type_name_prob': 75.40428161621094,\n",
       " 'graphical_appearance_name_prob': 27.07487678527832,\n",
       " 'perceived_colour_value_name_prob': 50.96394348144531,\n",
       " 'colour_group_code_prob': 41.485050201416016,\n",
       " 'index_name_prob': 62.60843276977539,\n",
       " 'index_group_name_prob': 38.46046447753906,\n",
       " 'section_name_prob': 455.3945007324219,\n",
       " 'department_name_prob': 531.75244140625,\n",
       " 'FN_prob': 22.918670654296875,\n",
       " 'Active_prob': 27.318485260009766,\n",
       " 'club_member_status_prob': 28.38362693786621,\n",
       " 'age_prob': 144.56809997558594,\n",
       " 'fashion_news_frequency_prob': 20.809524536132812,\n",
       " 'past_purchase_prob': 4505.01513671875,\n",
       " 'time_elapsed_last_purchase': 431.93896484375,\n",
       " 'number_of_purchase': 67.66783905029297}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_booster().get_score(importance_type='gain')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8acfcef-aff9-4f45-9c6e-de76393f56e1",
   "metadata": {},
   "source": [
    "****Local CV****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "11c269ac-e444-4de4-a565-6d1aaf6f58e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/21399652/ipykernel_193925/4083372006.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_x[group_name] = test_df[group_name]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.2 s, sys: 675 ms, total: 16.9 s\n",
      "Wall time: 15.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pred_df = make_prediction(model,dfs[idx][2].to_pandas(),features,label,k=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "44ea61a8-4a89-46c4-ac11-6ee333a5801e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "map@12 0.017833652590270584\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.017833652590270584"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_score(\n",
    "    pred_df,\n",
    "    dfs[idx][-1],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24241be-bbaf-4b9a-81ab-5266f61aafab",
   "metadata": {},
   "source": [
    "****Submission****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f0e357f1-bdc1-4fe6-a061-9739814accfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['product_group_name', 'product_type_name', 'graphical_appearance_name', 'perceived_colour_value_name', 'colour_group_code', 'index_name', 'index_group_name', 'section_name', 'department_name']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/21399652/ipykernel_193925/4083372006.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_x[group_name] = test_df[group_name]\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "article_features=[\n",
    "    'product_group_name', 'product_type_name', \n",
    "    'graphical_appearance_name', 'perceived_colour_value_name', 'colour_group_code', \n",
    "    'index_name', 'index_group_name', \n",
    "    'section_name', 'department_name',\n",
    "]\n",
    "customer_features=[\n",
    "    'FN','Active','club_member_status','age','fashion_news_frequency',\n",
    "    ]\n",
    "submission_df = cudf.read_csv('storage/sample_submission.csv')\n",
    "submission_df = construct_test_df(\n",
    "    submission_df[['customer_id']],\n",
    "    transactions[(transactions.t_dat > cudf.to_datetime('2020-09-07')) & (transactions.t_dat <= cudf.to_datetime('2020-09-22'))],\n",
    "    article_features,articles,customer_features,customers,\n",
    "    how='left',\n",
    ")\n",
    "submission_df = make_prediction(model,submission_df.to_pandas(),features,label,k=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "54385cf3-69f7-4d7b-bd17-26b20b922db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df['prediction'] = submission_df['prediction'].apply(lambda x: ' '.join(['0'+str(i) for i in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0f246357-a6b4-4b06-ab21-89353734fbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(base_dir,exist_ok=True)\n",
    "submission_df.to_csv(os.path.join(base_dir,'submission.csv'),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8e6a2e80-30a0-425b-8968-1f8edf603eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...</td>\n",
       "      <td>0751471001 0866731001 0448509014 0762846027 09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000423b00ade91418cceaf3b26c6af3dd342b51fd051e...</td>\n",
       "      <td>0448509014 0762846027 0866731001 0915529003 07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n",
       "      <td>0794321007 0866731001 0915529005 0714790020 09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2...</td>\n",
       "      <td>0762846027 0751471001 0924243001 0918522001 04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00006413d8573cd20ed7128e53b7b13819fe5cfc2d801f...</td>\n",
       "      <td>0751471001 0762846027 0918522001 0924243001 09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371975</th>\n",
       "      <td>ffffbbf78b6eaac697a8a5dfbfd2bfa8113ee5b403e474...</td>\n",
       "      <td>0448509014 0762846027 0866731001 0915529003 07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371976</th>\n",
       "      <td>ffffcd5046a6143d29a04fb8c424ce494a76e5cdf4fab5...</td>\n",
       "      <td>0448509014 0762846027 0866731001 0915529003 07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371977</th>\n",
       "      <td>ffffcf35913a0bee60e8741cb2b4e78b8a98ee5ff2e6a1...</td>\n",
       "      <td>0762846027 0884081001 0689365050 0794819001 09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371978</th>\n",
       "      <td>ffffd7744cebcf3aca44ae7049d2a94b87074c3d4ffe38...</td>\n",
       "      <td>0751471001 0866731001 0918522001 0714790020 04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371979</th>\n",
       "      <td>ffffd9ac14e89946416d80e791d064701994755c3ab686...</td>\n",
       "      <td>0751471001 0762846027 0714790020 0915529003 04...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1371980 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               customer_id  \\\n",
       "0        00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...   \n",
       "1        0000423b00ade91418cceaf3b26c6af3dd342b51fd051e...   \n",
       "2        000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...   \n",
       "3        00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2...   \n",
       "4        00006413d8573cd20ed7128e53b7b13819fe5cfc2d801f...   \n",
       "...                                                    ...   \n",
       "1371975  ffffbbf78b6eaac697a8a5dfbfd2bfa8113ee5b403e474...   \n",
       "1371976  ffffcd5046a6143d29a04fb8c424ce494a76e5cdf4fab5...   \n",
       "1371977  ffffcf35913a0bee60e8741cb2b4e78b8a98ee5ff2e6a1...   \n",
       "1371978  ffffd7744cebcf3aca44ae7049d2a94b87074c3d4ffe38...   \n",
       "1371979  ffffd9ac14e89946416d80e791d064701994755c3ab686...   \n",
       "\n",
       "                                                prediction  \n",
       "0        0751471001 0866731001 0448509014 0762846027 09...  \n",
       "1        0448509014 0762846027 0866731001 0915529003 07...  \n",
       "2        0794321007 0866731001 0915529005 0714790020 09...  \n",
       "3        0762846027 0751471001 0924243001 0918522001 04...  \n",
       "4        0751471001 0762846027 0918522001 0924243001 09...  \n",
       "...                                                    ...  \n",
       "1371975  0448509014 0762846027 0866731001 0915529003 07...  \n",
       "1371976  0448509014 0762846027 0866731001 0915529003 07...  \n",
       "1371977  0762846027 0884081001 0689365050 0794819001 09...  \n",
       "1371978  0751471001 0866731001 0918522001 0714790020 04...  \n",
       "1371979  0751471001 0762846027 0714790020 0915529003 04...  \n",
       "\n",
       "[1371980 rows x 2 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3c1df6-7497-4d81-a649-cffeb1207f2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAPIDSai-21.12",
   "language": "python",
   "name": "rapidsai-21.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
