{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f15cb93-59db-46d7-80a0-91a69dcd01da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "import lightgbm as lgb\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c03ecc79-bb9d-4599-86c8-adc55ecbd143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.2 s, sys: 1.79 s, total: 2.99 s\n",
      "Wall time: 9.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "transactions = cudf.read_csv('storage/transactions_train.csv')\n",
    "articles = cudf.read_csv('storage/articles.csv')\n",
    "customers = cudf.read_csv('storage/customers.csv')\n",
    "\n",
    "customers['FN'].fillna(0.,inplace=True)\n",
    "customers['Active'].fillna(0.,inplace=True)\n",
    "customers['club_member_status'].fillna('None',inplace=True)\n",
    "customers['age'] = customers['age'] / 10\n",
    "customers['age'] = customers['age'].astype(int)\n",
    "customers['fashion_news_frequency'] = customers['fashion_news_frequency'].str.lower().fillna('none')\n",
    "\n",
    "transactions['t_dat'] = cudf.to_datetime(transactions['t_dat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "873ff3cc-86d9-43da-98bd-0b5c3cf36255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def past_purchase_feature(df,transactions):\n",
    "    transactions['count'] = 1\n",
    "    \n",
    "    time_elapsed_last_purchase = transactions['t_dat'].max()-transactions[['customer_id','article_id','t_dat']].groupby(['customer_id','article_id'])['t_dat'].max()\n",
    "    time_elapsed_last_purchase = time_elapsed_last_purchase.dt.days\n",
    "    df = df.merge(time_elapsed_last_purchase,on=['article_id','customer_id'],how='left')\n",
    "    df = df.rename(columns={'t_dat':'time_elapsed_last_purchase'})\n",
    "    df['time_elapsed_last_purchase'].fillna(1e6,inplace=True)\n",
    "    \n",
    "    time_elapsed_first_release = transactions[['customer_id','article_id','t_dat']].groupby(['customer_id','article_id'])['t_dat'].min()-cudf.to_datetime('2018-09-01')\n",
    "    time_elapsed_first_release = time_elapsed_first_release.dt.days\n",
    "    df = df.merge(time_elapsed_first_release,on=['article_id','customer_id'],how='left')\n",
    "    df = df.rename(columns={'t_dat':'time_elapsed_first_release'})\n",
    "    df['time_elapsed_first_release'].fillna(1e6,inplace=True)\n",
    "    \n",
    "    past_purchase_prob = transactions[['customer_id','article_id','count']].groupby(['customer_id','article_id'])['count'].count().reset_index()\n",
    "    norm = transactions[['customer_id','article_id']].groupby('customer_id').count().reset_index().rename(columns={'article_id':'norm'})\n",
    "    past_purchase_prob = past_purchase_prob.merge(norm,on='customer_id')\n",
    "    past_purchase_prob['count'] = past_purchase_prob['count'] / past_purchase_prob['norm']\n",
    "    past_purchase_prob.drop(columns=['norm'],inplace=True)\n",
    "    df = df.merge(past_purchase_prob,on=['article_id','customer_id'],how='left')\n",
    "    df = df.rename(columns={'count':'past_purchase_prob'})\n",
    "    df['past_purchase_prob'].fillna(0.,inplace=True)\n",
    "    \n",
    "    total_purchase = transactions[['article_id','count']].groupby('article_id')['count'].count().reset_index().rename(columns={'count':'total_purchase'})\n",
    "    norm = transactions['count'].sum()\n",
    "    total_purchase['total_purchase'] = total_purchase['total_purchase'] / norm\n",
    "    df = df.merge(total_purchase,on='article_id',how='left')\n",
    "    df['total_purchase'].fillna(0.,inplace=True)\n",
    "    \n",
    "    number_of_purchase = transactions[['customer_id','count']].groupby('customer_id')['count'].count().reset_index().rename(columns={'count':'number_of_purchase'})\n",
    "    df = df.merge(number_of_purchase,on='customer_id',how='left')\n",
    "    df['number_of_purchase'].fillna(0.,inplace=True)\n",
    "    \n",
    "    repeated_purchase = transactions[['customer_id','article_id','count']].groupby(['customer_id','article_id'])['count'].count().reset_index().rename(columns={'count':'repeated_purchase'})\n",
    "    df = df.merge(repeated_purchase,on=['customer_id','article_id'],how='left')\n",
    "    \n",
    "    min_dat_purchase = transactions.groupby(['article_id'])['t_dat'].min()\n",
    "    max_dat_purchase = transactions.groupby(['article_id'])['t_dat'].max()\n",
    "    sale_duration = (max_dat_purchase - min_dat_purchase).to_frame().reset_index().rename(columns={'t_dat':'duration'})\n",
    "    sale_duration['duration'] = sale_duration['duration'].dt.days\n",
    "    sale_count = transactions.groupby(['article_id'])['t_dat'].count().to_frame().reset_index().rename(columns={'t_dat':'count'})\n",
    "    sale_rate = sale_duration.merge(sale_count,on='article_id')\n",
    "    sale_rate = sale_rate.loc[sale_rate['duration']!=0]\n",
    "    sale_rate['sale_rate'] = sale_rate['count'] / sale_rate['duration']\n",
    "    df = df.merge(sale_rate[['article_id','sale_rate']],on='article_id',how='left')\n",
    "\n",
    "    return df\n",
    "    \n",
    "def article_feature_prob_vector(df,transactions,articles,article_features,postfix='_prob',customer_group_name='customer_id'):\n",
    "    transactions['count'] = 1\n",
    "    if customer_group_name != 'customer_id':\n",
    "        df = df.merge(customers[['customer_id',customer_group_name]],on='customer_id',how='left')\n",
    "        transactions = transactions.merge(customers[['customer_id',customer_group_name]],on='customer_id',how='left')\n",
    "    for article_feature in article_features:\n",
    "        transactions = transactions.merge(articles[['article_id',article_feature]],on='article_id',how='left')\n",
    "        norm = transactions.groupby([customer_group_name])['count'].count().reset_index()\n",
    "        norm.rename(columns={'count':'norm'},inplace=True)\n",
    "        count = transactions.groupby([customer_group_name,article_feature])['count'].count().reset_index()\n",
    "        count = count.merge(norm,on=customer_group_name)\n",
    "        count['count'] = count['count'] / count['norm']\n",
    "        count = count.rename(columns={'count':article_feature+postfix})\n",
    "        count = count[[customer_group_name,article_feature,article_feature+postfix]]\n",
    "        del(norm)\n",
    "        df = df.merge(articles[['article_id',article_feature]],on='article_id',how='left')\n",
    "        df = df.merge(count,on=[customer_group_name,article_feature],how='left')\n",
    "    return df\n",
    "\n",
    "def customer_feature_prob_vector(df,transactions,customers,customer_features,postfix='_prob'):\n",
    "    transactions['count'] = 1\n",
    "    for customer_feature in customer_features:\n",
    "        transactions = transactions.merge(customers[['customer_id',customer_feature]],on='customer_id',how='left')\n",
    "        norm = transactions.groupby(['article_id'])['count'].count().reset_index()\n",
    "        norm.rename(columns={'count':'norm'},inplace=True)\n",
    "        count = transactions.groupby(['article_id',customer_feature])['count'].count().reset_index()\n",
    "        count = count.merge(norm,on='article_id')\n",
    "        count['count'] = count['count'] / count['norm']\n",
    "        count = count.rename(columns={'count':customer_feature+postfix})\n",
    "        count = count[['article_id',customer_feature,customer_feature+postfix]]\n",
    "        del(norm)\n",
    "        df = df.merge(customers[['customer_id',customer_feature]],on='customer_id',how='left')\n",
    "        df = df.merge(count,on=['article_id',customer_feature],how='left')\n",
    "    return df\n",
    "\n",
    "def construct_feature_df(\n",
    "        df,transactions,\n",
    "        article_features,\n",
    "        articles,\n",
    "        customer_features,\n",
    "        customers,\n",
    "        general_features=['article_id','customer_id'],\n",
    "    ):\n",
    "    df = article_feature_prob_vector(df,transactions,articles,article_features)\n",
    "    df = customer_feature_prob_vector(df,transactions,customers,customer_features)\n",
    "    df = past_purchase_feature(df,transactions)\n",
    "    df = df[\n",
    "            general_features+[f for f in df.columns if '_prob' in f] + \n",
    "            ['total_purchase','time_elapsed_last_purchase','past_purchase_prob','number_of_purchase','time_elapsed_first_release','repeated_purchase']\n",
    "        ]\n",
    "    return df\n",
    "\n",
    "def construct_candidate_dict(transactions_3w):\n",
    "    purchase_dict_3w = {}\n",
    "    for i,x in enumerate(zip(transactions_3w['customer_id'], transactions_3w['article_id'])):\n",
    "        cust_id, art_id = x\n",
    "        if cust_id not in purchase_dict_3w:\n",
    "            purchase_dict_3w[cust_id] = {}\n",
    "        if art_id not in purchase_dict_3w[cust_id]:\n",
    "            purchase_dict_3w[cust_id][art_id] = 0\n",
    "        purchase_dict_3w[cust_id][art_id] += 1\n",
    "    return purchase_dict_3w\n",
    "\n",
    "def construct_candidate_df(\n",
    "        test_df,transactions,\n",
    "        nweek=8,\n",
    "        n_popular_item=50,\n",
    "        n_total_item=None,\n",
    "    ):\n",
    "    \n",
    "    recent_transactions = {}\n",
    "    purchase_dict = {}\n",
    "    for i in range(1,nweek+1):\n",
    "        recent_transactions[i] = transactions[(transactions.t_dat>transactions.t_dat.max()-i*pd.Timedelta(7,unit='day'))&(transactions.t_dat<=transactions.t_dat.max()-(i-1)*pd.Timedelta(7,unit='day'))].to_pandas()\n",
    "        purchase_dict[i] = construct_candidate_dict(recent_transactions[i])\n",
    "    \n",
    "    if 1 in recent_transactions:\n",
    "        most_popular_items_1w_all = list((recent_transactions[1]['article_id'].value_counts()).index)[:n_popular_item]\n",
    "    else:\n",
    "        most_popular_items_1w_all = list(transactions['article_id'].value_counts().index.to_arrow().to_pylist())[:n_popular_item]\n",
    "    \n",
    "    pred_df = pd.DataFrame()\n",
    "    pred_df['customer_id'] = test_df['customer_id'].unique()\n",
    "    \n",
    "    prediction_list = []\n",
    "    \n",
    "    for i, cust_id in enumerate(pred_df['customer_id']):\n",
    "        s = []\n",
    "        total_purchase_dict = {}\n",
    "        \n",
    "        for i,purchase_dict_week in purchase_dict.items():\n",
    "            if cust_id in purchase_dict_week:\n",
    "                l = sorted((purchase_dict_week[cust_id]).items(), key=lambda x: x[1], reverse=True)\n",
    "                l = [y[0] for y in l]\n",
    "                for aid in l:\n",
    "                    if aid not in total_purchase_dict:\n",
    "                        total_purchase_dict[aid] = 1\n",
    "                    else:\n",
    "                        total_purchase_dict[aid] += 1\n",
    "\n",
    "        for aid in most_popular_items_1w_all[:n_popular_item]:\n",
    "            if aid not in total_purchase_dict:\n",
    "                total_purchase_dict[aid] = 1\n",
    "            else:\n",
    "                total_purchase_dict[aid] += 1\n",
    "\n",
    "        if n_total_item is not None:\n",
    "            total_purchase_dict = {k: v for k, v in sorted(total_purchase_dict.items(), key=lambda item: item[1], reverse=True)}\n",
    "            s = list(total_purchase_dict.keys())[:n_total_item]\n",
    "        else:\n",
    "            s = list(total_purchase_dict.keys())\n",
    "        \n",
    "        prediction_list.append(s)\n",
    "        \n",
    "    pred_df['article_id'] = prediction_list\n",
    "    \n",
    "    return pred_df\n",
    "\n",
    "def construct_test_df(test_df,transactions,article_features,articles,customer_features,customers,how='outer',n_popular_item=10):\n",
    "    test_df = construct_candidate_df(test_df,transactions,n_popular_item=n_popular_item).explode(['article_id']).reset_index(drop=True)\n",
    "    test_df = cudf.from_pandas(test_df)\n",
    "    test_df = construct_feature_df(test_df,transactions,article_features,articles,customer_features,customers,general_features=['article_id','customer_id'])\n",
    "    test_df = test_df.fillna(0.)\n",
    "    test_df['article_id'] = test_df['article_id'].astype(int)\n",
    "    test_df = test_df.sort_values(['customer_id','article_id']).reset_index(drop=True)\n",
    "    return test_df\n",
    "\n",
    "def construct_recent_purchase_df(\n",
    "        test_df,transactions,\n",
    "        nweek=3,feature_name='recent_purchase',\n",
    "    ):\n",
    "    \n",
    "    recent_transactions = {}\n",
    "    purchase_dict = {}\n",
    "    for i in range(1,nweek+1):\n",
    "        recent_transactions[i] = transactions[(transactions.t_dat>transactions.t_dat.max()-i*pd.Timedelta(7,unit='day'))&(transactions.t_dat<=transactions.t_dat.max()-(i-1)*pd.Timedelta(7,unit='day'))]\n",
    "        purchase_dict[i] = construct_candidate_dict(recent_transactions[i])\n",
    "\n",
    "    most_popular_items_1w = list((recent_transactions[1]['article_id'].value_counts()).index)[:12]\n",
    "        \n",
    "    pred_df = test_df[['customer_id']]\n",
    "    article_id_list,recent_purchase_score_list = [],[]\n",
    "    \n",
    "    for i, cust_id in enumerate(\n",
    "        test_df['customer_id'].values.reshape((-1,))\n",
    "    ):\n",
    "        s = []\n",
    "        total_purchase_dict = {}\n",
    "        \n",
    "        for i,purchase_dict_week in purchase_dict.items():\n",
    "            if cust_id in purchase_dict_week:\n",
    "                l = sorted((purchase_dict_week[cust_id]).items(), key=lambda x: x[1], reverse=True)\n",
    "                l = [y[0] for y in l]\n",
    "                for aid in l:\n",
    "                    if aid not in total_purchase_dict:\n",
    "                        total_purchase_dict[aid] = 1\n",
    "                    else:\n",
    "                        total_purchase_dict[aid] += 1\n",
    "                        \n",
    "#         for aid in most_popular_items_1w[:12]:\n",
    "#             if aid not in total_purchase_dict:\n",
    "#                 total_purchase_dict[aid] = 1\n",
    "#             else:\n",
    "#                 total_purchase_dict[aid] += 1\n",
    "\n",
    "        total_purchase_dict = {k: v for k, v in sorted(total_purchase_dict.items(), key=lambda item: item[1], reverse=True)}\n",
    "        article_ids = list(total_purchase_dict.keys())\n",
    "        recent_purchase_scores = list(total_purchase_dict.values())\n",
    "        \n",
    "        article_id_list.append(article_ids)\n",
    "        recent_purchase_score_list.append(recent_purchase_scores)\n",
    "        \n",
    "    pred_df['recent_purchase_article_id'] = article_id_list\n",
    "    pred_df['recent_purchase_score'] = recent_purchase_score_list\n",
    "    \n",
    "    return pred_df\n",
    "\n",
    "def construct_time_period_purchase_df(\n",
    "        test_df,recent_transactions,\n",
    "        feature_name,\n",
    "        nitem=50,\n",
    "    ):\n",
    "    \n",
    "    purchase_dict = construct_candidate_dict(recent_transactions)\n",
    "\n",
    "    pred_df = test_df[['customer_id']]\n",
    "    article_id_list,score_list = [],[]\n",
    "    \n",
    "    for i, cust_id in enumerate(\n",
    "        test_df['customer_id'].values.reshape((-1,))\n",
    "    ):\n",
    "        s = []\n",
    "        total_purchase_dict = {}\n",
    "\n",
    "        if cust_id in purchase_dict:\n",
    "            l = sorted((purchase_dict[cust_id]).items(), key=lambda x: x[1], reverse=True)\n",
    "            l = [y[0] for y in l]\n",
    "            for aid in l:\n",
    "                if aid not in total_purchase_dict:\n",
    "                    total_purchase_dict[aid] = 1\n",
    "                else:\n",
    "                    total_purchase_dict[aid] += 1\n",
    "\n",
    "        total_purchase_dict = {k: v for k, v in sorted(total_purchase_dict.items(), key=lambda item: item[1], reverse=True)}\n",
    "        article_ids = list(total_purchase_dict.keys())[:nitem]\n",
    "        scores = list(total_purchase_dict.values())[:nitem]\n",
    "        \n",
    "        article_id_list.append(article_ids)\n",
    "        score_list.append(scores)\n",
    "        \n",
    "    pred_df[feature_name+'_article_id'] = article_id_list\n",
    "    pred_df[feature_name+'_score'] = score_list\n",
    "    \n",
    "    return pred_df\n",
    "\n",
    "def construct_popular_purchase_df(\n",
    "        test_df,transactions,\n",
    "        feature_name='popular_purchase',\n",
    "        nitem=200,\n",
    "    ):\n",
    "        \n",
    "    most_popular_items = list((transactions['article_id'].value_counts()).index)[:nitem] \n",
    "    most_popular_scores = list((transactions['article_id'].value_counts()))[:nitem]\n",
    "\n",
    "    pred_df = test_df[['customer_id']]\n",
    "        \n",
    "    pred_df[feature_name+'_article_id'] = [most_popular_items]*len(pred_df)\n",
    "    pred_df[feature_name+'_score'] = [most_popular_scores]*len(pred_df)\n",
    "    \n",
    "    return pred_df\n",
    "\n",
    "def construct_gt_df(test_transactions):\n",
    "    gt_df = test_transactions.to_pandas().groupby('customer_id')['article_id'].agg(lambda x: x.tolist()).reset_index()\n",
    "    gt_df.columns = ['customer_id','ground_truth']\n",
    "    return gt_df\n",
    "\n",
    "def make_prediction(model,test_df,features,label,k=100,group_name='customer_id'):\n",
    "    test_x = test_df[features]\n",
    "    test_pred = model.predict(test_x)\n",
    "    test_x[group_name] = test_df[group_name]\n",
    "    test_x['past_purchase_article_id'] = test_df['article_id']\n",
    "    test_x['past_purchase_score'] = test_pred\n",
    "    pred_df = test_x.groupby('customer_id') \\\n",
    "                .apply(lambda x: x.sort_values('past_purchase_score',ascending=False)['past_purchase_article_id'].tolist()) \\\n",
    "                .reset_index()\n",
    "    pred_df.columns = ['customer_id','past_purchase_article_id']\n",
    "    past_purchase_score = test_x.groupby('customer_id') \\\n",
    "            .apply(lambda x: x.sort_values('past_purchase_score',ascending=False)['past_purchase_score'].tolist()).reset_index()\n",
    "    past_purchase_score.columns = ['customer_id','past_purchase_score']\n",
    "    pred_df = pred_df.merge(past_purchase_score,on='customer_id')\n",
    "    return pred_df[['customer_id','past_purchase_article_id','past_purchase_score']]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd6aea15-b9b2-4545-9b26-43e489dd895b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_rerank_df(\n",
    "    customer_df,past_transactions,\n",
    "    articles,customers,\n",
    "    past_purchase_model_path,\n",
    "    label='label',\n",
    "    gt_df=None,\n",
    "    verbose=True,\n",
    "    article_features=[\n",
    "        'product_type_name','product_group_name',\n",
    "        'graphical_appearance_name','colour_group_name',\n",
    "        'perceived_colour_value_name','perceived_colour_master_name',\n",
    "        'department_name', 'index_name',\n",
    "        'index_group_name','section_name',\n",
    "        'garment_group_name',\n",
    "    ],\n",
    "    customer_features=[\n",
    "        'FN','Active','club_member_status','age','fashion_news_frequency',\n",
    "    ],\n",
    "):\n",
    "    past_purchase_df = construct_test_df(\n",
    "        customer_df,past_transactions,\n",
    "        article_features,articles,\n",
    "        customer_features,customers,\n",
    "        how='outer',n_popular_item=90\n",
    "    )    \n",
    "    bst = lgb.Booster(model_file=past_purchase_model_path)\n",
    "    features = [c for c in past_purchase_df.columns if c not in ['article_id','customer_id','label','index','group_size']]\n",
    "    past_purchase_df = make_prediction(bst,past_purchase_df.to_pandas(),features,label)\n",
    "    rerank_df = past_purchase_df.explode(['past_purchase_article_id','past_purchase_score']).rename(columns={'past_purchase_article_id':'article_id'})\n",
    "\n",
    "    for iweek in range(1,4):\n",
    "        feature_name = 'recent_purchase_{:d}w'.format(iweek)\n",
    "        recent_transactions = past_transactions[\n",
    "            (past_transactions.t_dat>past_transactions.t_dat.max()-iweek*pd.Timedelta(7,unit='day'))&\n",
    "            (past_transactions.t_dat<=past_transactions.t_dat.max()-(iweek-1)*pd.Timedelta(7,unit='day'))\n",
    "        ]\n",
    "        recent_purchase_df = construct_time_period_purchase_df(\n",
    "           customer_df,recent_transactions.to_pandas(),feature_name,\n",
    "        )\n",
    "        recent_purchase_df = recent_purchase_df.explode([feature_name+'_article_id',feature_name+'_score']).rename(columns={feature_name+'_article_id':'article_id'})\n",
    "        rerank_df = rerank_df.merge(recent_purchase_df,on=['customer_id','article_id'],how='outer')\n",
    "    \n",
    "    recent_purchase_df = construct_recent_purchase_df(\n",
    "       customer_df,past_transactions.to_pandas(),\n",
    "    )\n",
    "    recent_purchase_df = recent_purchase_df.explode(['recent_purchase_article_id','recent_purchase_score']).rename(columns={'recent_purchase_article_id':'article_id'})\n",
    "    rerank_df = rerank_df.merge(recent_purchase_df,on=['customer_id','article_id'],how='outer')\n",
    "    \n",
    "    for iweek in range(1,4):\n",
    "        feature_name = 'popular_purchase_{:d}w'.format(iweek)\n",
    "        recent_transactions = past_transactions[\n",
    "            (past_transactions.t_dat>past_transactions.t_dat.max()-iweek*pd.Timedelta(7,unit='day'))&\n",
    "            (past_transactions.t_dat<=past_transactions.t_dat.max()-(iweek-1)*pd.Timedelta(7,unit='day'))\n",
    "        ]\n",
    "        popular_purchase_df = construct_popular_purchase_df(\n",
    "            customer_df,recent_transactions.to_pandas(),feature_name,\n",
    "        )\n",
    "        popular_purchase_df = popular_purchase_df.explode([feature_name+'_article_id',feature_name+'_score']).rename(columns={feature_name+'_article_id':'article_id'})\n",
    "        rerank_df = rerank_df.merge(popular_purchase_df,on=['customer_id','article_id'],how='outer')\n",
    "        \n",
    "    feature_name = 'popular_purchase_123w'\n",
    "    recent_transactions = past_transactions[\n",
    "        (past_transactions.t_dat>past_transactions.t_dat.max()-4*pd.Timedelta(7,unit='day'))&\n",
    "        (past_transactions.t_dat<=past_transactions.t_dat.max()-pd.Timedelta(7,unit='day'))\n",
    "    ]\n",
    "    popular_purchase_df = construct_popular_purchase_df(\n",
    "        customer_df,recent_transactions.to_pandas(),feature_name,\n",
    "    )\n",
    "    popular_purchase_df = popular_purchase_df.explode([feature_name+'_article_id',feature_name+'_score']).rename(columns={feature_name+'_article_id':'article_id'})\n",
    "    rerank_df = rerank_df.merge(popular_purchase_df,on=['customer_id','article_id'],how='outer')\n",
    "    \n",
    "    if gt_df is not None:\n",
    "        tmp_gt_df = gt_df.copy()\n",
    "        tmp_gt_df['label'] = 1\n",
    "        tmp_gt_df = tmp_gt_df.rename(columns={'ground_truth':'article_id'})\n",
    "        rerank_df = rerank_df.merge(tmp_gt_df[['customer_id','article_id','label']].explode('article_id'),on=['customer_id','article_id'],how='outer')\n",
    "    \n",
    "    rerank_df['past_purchase_score'].fillna(rerank_df['past_purchase_score'].min()-1.,inplace=True)\n",
    "    rerank_df.fillna(0.,inplace=True)\n",
    "    \n",
    "    return rerank_df\n",
    "\n",
    "def evaluate_score(pred_df,gt_df,k=12,verbose=True,group_name='customer_id',pred_name='prediction'):\n",
    "    from metric import mapk\n",
    "    eval_df = gt_df.merge(pred_df,on=group_name,how='left')\n",
    "    score = mapk(eval_df['ground_truth'].tolist(),eval_df[pred_name].tolist())\n",
    "    if verbose: print('map@'+str(k),score)\n",
    "    return score\n",
    "\n",
    "def construct_sub_df(test_df,preds,k=12):\n",
    "    pred_df = pd.DataFrame()\n",
    "    pred_df['customer_id'] = test_df['customer_id']\n",
    "    pred_df['article_id'] = test_df['article_id']\n",
    "    pred_df['prediction'] = preds\n",
    "    pred_df = pred_df.groupby('customer_id') \\\n",
    "                    .apply(lambda x: x.sort_values(['customer_id','prediction'],ascending=False)['article_id'].tolist()[:k]) \\\n",
    "                    .reset_index()\n",
    "    pred_df.columns = ['customer_id','prediction']\n",
    "    return pred_df\n",
    "\n",
    "def feval(preds,test_df,test_gt_df,k=12):\n",
    "    pred_df = pd.DataFrame()\n",
    "    pred_df['customer_id'] = test_df['customer_id']\n",
    "    pred_df['article_id'] = test_df['article_id']\n",
    "    pred_df['prediction'] = preds\n",
    "    pred_df = pred_df.groupby('customer_id') \\\n",
    "                    .apply(lambda x: x.sort_values(['customer_id','prediction'],ascending=False)['article_id'].tolist()[:k]) \\\n",
    "                    .reset_index()\n",
    "    pred_df.columns = ['customer_id','prediction']\n",
    "    score = evaluate_score(pred_df,test_gt_df,group_name='customer_id',verbose=False)\n",
    "    return 'MAP@'+str(k), score, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fa3524e-e68e-4518-a822-c42f6d6bad71",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_start_time = '2020-09-07'\n",
    "trn_end_time = '2020-09-15'\n",
    "test_start_time = '2020-09-15'\n",
    "test_end_time = '2020-09-22'\n",
    "\n",
    "trn_start_time = cudf.to_datetime(trn_start_time)\n",
    "trn_end_time = cudf.to_datetime(trn_end_time)\n",
    "test_start_time = cudf.to_datetime(test_start_time)\n",
    "test_end_time = cudf.to_datetime(test_end_time)\n",
    "\n",
    "past_transactions = transactions[(transactions.t_dat > cudf.to_datetime('2020-01-01')) & (transactions.t_dat <= trn_end_time)]\n",
    "trn_transactions = transactions[(transactions.t_dat > trn_start_time) & (transactions.t_dat <= trn_end_time)]\n",
    "test_transactions = transactions[(transactions.t_dat > test_start_time) & (transactions.t_dat <= test_end_time)]\n",
    "\n",
    "trn_gt_df = construct_gt_df(trn_transactions)\n",
    "test_gt_df = construct_gt_df(test_transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e9b56dd-1ff9-4636-b2c2-4050f0122dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/24675499/ipykernel_59638/3206644925.py:289: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_x[group_name] = test_df[group_name]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 5s, sys: 35.3 s, total: 3min 40s\n",
      "Wall time: 3min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trn_df = construct_rerank_df(\n",
    "    trn_gt_df[['customer_id']],past_transactions,\n",
    "    articles,customers,\n",
    "    'storage/output/220325_lightgbm_training/220325_dataset_2020-06-01_2020-08-01_2020-09-15_2020-09-22_score:0.0230037_objective:lambdarank_metric:map@12_boosting:dart_seed:0_learning_rate:0.03_num_threads:8_num_iterations:15_early_stopping_round:None.bin',\n",
    "    label='label',\n",
    "    gt_df=trn_gt_df,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22c94398-7c01-4216-bea5-c5268a7c80da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/24675499/ipykernel_59638/3206644925.py:289: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_x[group_name] = test_df[group_name]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 32s, sys: 30.8 s, total: 3min 3s\n",
      "Wall time: 2min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_df = construct_rerank_df(\n",
    "    test_gt_df[['customer_id']],past_transactions,\n",
    "    articles,customers,\n",
    "    'storage/output/220325_lightgbm_training/220325_dataset_2020-06-01_2020-08-01_2020-09-15_2020-09-22_score:0.0230037_objective:lambdarank_metric:map@12_boosting:dart_seed:0_learning_rate:0.03_num_threads:8_num_iterations:15_early_stopping_round:None.bin',\n",
    "    label='label',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b411493-32c5-4ea3-9811-45dc52af4580",
   "metadata": {},
   "source": [
    "****Reranking with Logistic Regression****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bff91ba7-b3e3-4d8a-82e7-a6b71380e948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['customer_id',\n",
      " 'article_id',\n",
      " 'past_purchase_score',\n",
      " 'recent_purchase_1w_score',\n",
      " 'recent_purchase_2w_score',\n",
      " 'recent_purchase_3w_score',\n",
      " 'recent_purchase_score',\n",
      " 'popular_purchase_1w_score',\n",
      " 'popular_purchase_2w_score',\n",
      " 'popular_purchase_3w_score',\n",
      " 'popular_purchase_123w_score',\n",
      " 'label']\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(trn_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e0e89a4-33dd-4d6a-9b41-ada417ad2452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "past_purchase_score recent_purchase_1w_score recent_purchase_2w_score recent_purchase_3w_score popular_purchase_1w_score popular_purchase_2w_score popular_purchase_3w_score\n"
     ]
    }
   ],
   "source": [
    "features = [\n",
    "    'past_purchase_score',\n",
    "    'recent_purchase_1w_score',\n",
    "    'recent_purchase_2w_score',\n",
    "    'recent_purchase_3w_score',\n",
    "    #'recent_purchase_score',\n",
    "    'popular_purchase_1w_score',\n",
    "     'popular_purchase_2w_score',\n",
    "     'popular_purchase_3w_score',\n",
    "#     'popular_purchase_4w_score',\n",
    "#     'popular_purchase_5w_score',\n",
    "#     'popular_purchase_6w_score',\n",
    "#     'popular_purchase_7w_score',\n",
    "#     'popular_purchase_8w_score',\n",
    "#     'popular_purchase_9w_score',\n",
    "#     'popular_purchase_10w_score',\n",
    "#     'popular_purchase_11w_score',\n",
    "#     'popular_purchase_123w_score',\n",
    "]\n",
    "target = 'label'\n",
    "print(' '.join(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "482805e3-11fe-4c00-bb61-f206be1a002e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>past_purchase_score</th>\n",
       "      <th>recent_purchase_1w_score</th>\n",
       "      <th>recent_purchase_2w_score</th>\n",
       "      <th>recent_purchase_3w_score</th>\n",
       "      <th>popular_purchase_1w_score</th>\n",
       "      <th>popular_purchase_2w_score</th>\n",
       "      <th>popular_purchase_3w_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.232283</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.035045</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>407.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.029059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>607.0</td>\n",
       "      <td>724.0</td>\n",
       "      <td>846.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.023665</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>453.0</td>\n",
       "      <td>683.0</td>\n",
       "      <td>701.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.020612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>609.0</td>\n",
       "      <td>529.0</td>\n",
       "      <td>297.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30374491</th>\n",
       "      <td>-1.386569</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30374492</th>\n",
       "      <td>-1.386569</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30374493</th>\n",
       "      <td>-1.386569</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30374494</th>\n",
       "      <td>-1.386569</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30374495</th>\n",
       "      <td>-1.386569</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30374496 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          past_purchase_score  recent_purchase_1w_score  \\\n",
       "0                    0.232283                       1.0   \n",
       "1                    0.035045                       0.0   \n",
       "2                    0.029059                       0.0   \n",
       "3                    0.023665                       0.0   \n",
       "4                    0.020612                       0.0   \n",
       "...                       ...                       ...   \n",
       "30374491            -1.386569                       0.0   \n",
       "30374492            -1.386569                       0.0   \n",
       "30374493            -1.386569                       0.0   \n",
       "30374494            -1.386569                       0.0   \n",
       "30374495            -1.386569                       0.0   \n",
       "\n",
       "          recent_purchase_2w_score  recent_purchase_3w_score  \\\n",
       "0                              0.0                       0.0   \n",
       "1                              0.0                       0.0   \n",
       "2                              0.0                       0.0   \n",
       "3                              0.0                       0.0   \n",
       "4                              0.0                       0.0   \n",
       "...                            ...                       ...   \n",
       "30374491                       0.0                       0.0   \n",
       "30374492                       0.0                       0.0   \n",
       "30374493                       0.0                       0.0   \n",
       "30374494                       0.0                       0.0   \n",
       "30374495                       0.0                       0.0   \n",
       "\n",
       "          popular_purchase_1w_score  popular_purchase_2w_score  \\\n",
       "0                               0.0                        0.0   \n",
       "1                             266.0                      377.0   \n",
       "2                             607.0                      724.0   \n",
       "3                             453.0                      683.0   \n",
       "4                             609.0                      529.0   \n",
       "...                             ...                        ...   \n",
       "30374491                        0.0                        0.0   \n",
       "30374492                        0.0                        0.0   \n",
       "30374493                        0.0                        0.0   \n",
       "30374494                        0.0                        0.0   \n",
       "30374495                        0.0                        0.0   \n",
       "\n",
       "          popular_purchase_3w_score  \n",
       "0                               0.0  \n",
       "1                             407.0  \n",
       "2                             846.0  \n",
       "3                             701.0  \n",
       "4                             297.0  \n",
       "...                             ...  \n",
       "30374491                        0.0  \n",
       "30374492                        0.0  \n",
       "30374493                        0.0  \n",
       "30374494                        0.0  \n",
       "30374495                        0.0  \n",
       "\n",
       "[30374496 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "517fcc8d-4bb2-46b3-84d7-a16117b29918",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87a7cab2-dd17-442b-b6cd-bf3cba372e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.10032804e+01  1.93351856e+01  1.07022535e+01 -1.16369597e+00\n",
      "   1.91058088e-03 -5.22323259e-04 -8.89565558e-04]] [-12.10194635]\n",
      "CPU times: user 13min 6s, sys: 4min 51s, total: 17min 57s\n",
      "Wall time: 11min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = LogisticRegression(max_iter=1000,random_state=1).fit(trn_df[features],trn_df[target])\n",
    "print(clf.coef_, clf.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "465b3705-7604-4b29-aa77-c76eeff636d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02409009606820875\n",
      "CPU times: user 52.9 s, sys: 3.08 s, total: 56 s\n",
      "Wall time: 55.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = clf.predict_proba(test_df[features])\n",
    "_,score,_ = feval(preds[:,1],test_df,test_gt_df,k=12)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fcb562-fe4e-4388-b11b-777ccfb0b77b",
   "metadata": {},
   "source": [
    "****Construct ground truth vs prediction dataframe for model evalution****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c6412ce-44b7-4eab-ba4b-73da8c5d00c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = construct_sub_df(test_df,preds[:,1],k=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2cc11872-2739-432d-9ec6-e9b20e34f0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = eval_df.merge(test_gt_df,on='customer_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1bea36e5-a973-4e33-b3e3-a63cb736e0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df['gt_pred_overlap'] = eval_df.apply(lambda x: set(x['prediction']).intersection(x['ground_truth']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6857bbf3-2c1e-4838-ab80-309c8b5b7ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df['n_gt_pred_overlap'] = eval_df['gt_pred_overlap'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d52689da-f421-4c62-aea4-1db28371bc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df.to_csv('eval_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d110f9c-2021-4062-a43e-bf73babfe7f7",
   "metadata": {},
   "source": [
    "****Cross validation****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "28c9aafc-5eb5-4396-98e0-f41f83800e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "past_purchase_score recent_purchase_score popular_purchase_2w_score popular_purchase_3w_score\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Construct trn_df,test_df,gt_df\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/23024933/ipykernel_246233/677110032.py:287: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_x[group_name] = test_df[group_name]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate individual score\n",
      "map@12 0.0218197403088478\n",
      "Past purchase score:  0.0218197403088478\n",
      "map@12 0.0224274351400841\n",
      "Rast purchase score:  0.0224274351400841\n",
      "Fit logistic regression\n",
      "[[ 5.35871593e+01  3.33788170e+00 -4.01850858e-03 -1.45003312e-03]] [-7.68883237]\n",
      "Evaluate score\n",
      "Combined score 0.02300798395803935\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Construct trn_df,test_df,gt_df\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/23024933/ipykernel_246233/677110032.py:287: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_x[group_name] = test_df[group_name]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate individual score\n",
      "map@12 0.02120180749419716\n",
      "Past purchase score:  0.02120180749419716\n",
      "map@12 0.02081457478481509\n",
      "Rast purchase score:  0.02081457478481509\n",
      "Fit logistic regression\n",
      "[[ 6.74606785e+01  9.70919996e-01 -1.45067508e-03 -4.34159804e-04]] [-9.70567644]\n",
      "Evaluate score\n",
      "Combined score 0.02118735517461465\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Construct trn_df,test_df,gt_df\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/23024933/ipykernel_246233/677110032.py:287: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_x[group_name] = test_df[group_name]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate individual score\n",
      "map@12 0.022834035692751553\n",
      "Past purchase score:  0.022834035692751553\n",
      "map@12 0.023001215145791547\n",
      "Rast purchase score:  0.023001215145791547\n",
      "Fit logistic regression\n",
      "[[ 3.96098123e+01  3.46879209e+00 -3.65995529e-03 -4.95104468e-04]] [-7.192397]\n",
      "Evaluate score\n",
      "Combined score 0.024440467490615764\n",
      "CPU times: user 21min, sys: 5min 47s, total: 26min 47s\n",
      "Wall time: 22min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "features = [\n",
    "    'past_purchase_score',\n",
    "    #'recent_purchase_1w_score',\n",
    "    #'recent_purchase_2w_score',\n",
    "    #'recent_purchase_3w_score',\n",
    "    'recent_purchase_score',\n",
    "    #'popular_purchase_1w_score',\n",
    "    'popular_purchase_2w_score',\n",
    "    'popular_purchase_3w_score',\n",
    "    #'popular_purchase_123w_score',\n",
    "]\n",
    "target = 'label'\n",
    "print(' '.join(features))\n",
    "\n",
    "for i,(trn_start_time,trn_end_time,test_start_time,test_end_time,model_path) in enumerate([\n",
    "        (\n",
    "            '2020-08-24','2020-08-31','2020-08-31','2020-09-07',\n",
    "            'storage/output/220325_lightgbm_training/220325_dataset_2020-05-17_2020-07-17_2020-09-01_2020-09-07_score:0.022701_objective:lambdarank_metric:map@12_boosting:dart_seed:0_learning_rate:0.03_num_threads:8_num_iterations:15_early_stopping_round:None.bin',\n",
    "        ),\n",
    "        (\n",
    "            '2020-08-31','2020-09-07','2020-09-07','2020-09-15',\n",
    "            'storage/output/220325_lightgbm_training/220325_dataset_2020-05-24_2020-07-24_2020-09-07_2020-09-15_score:0.020357_objective:lambdarank_metric:map@12_boosting:dart_seed:0_learning_rate:0.03_num_threads:8_num_iterations:15_early_stopping_round:None.bin',\n",
    "        ),\n",
    "        (\n",
    "            '2020-09-07','2020-09-15','2020-09-15','2020-09-22',\n",
    "            'storage/output/220325_lightgbm_training/220325_dataset_2020-06-01_2020-08-01_2020-09-15_2020-09-22_score:0.0230037_objective:lambdarank_metric:map@12_boosting:dart_seed:0_learning_rate:0.03_num_threads:8_num_iterations:15_early_stopping_round:None.bin',\n",
    "        ),\n",
    "    ]):\n",
    "    \n",
    "    print('-'*100)\n",
    "    \n",
    "    trn_start_time = cudf.to_datetime(trn_start_time)\n",
    "    trn_end_time = cudf.to_datetime(trn_end_time)\n",
    "    test_start_time = cudf.to_datetime(test_start_time)\n",
    "    test_end_time = cudf.to_datetime(test_end_time)\n",
    "\n",
    "    past_transactions = transactions[(transactions.t_dat > cudf.to_datetime('2020-01-01')) & (transactions.t_dat <= trn_end_time)]\n",
    "    trn_transactions = transactions[(transactions.t_dat > trn_start_time) & (transactions.t_dat <= trn_end_time)]\n",
    "    test_transactions = transactions[(transactions.t_dat > test_start_time) & (transactions.t_dat <= test_end_time)]\n",
    "\n",
    "    print('Construct trn_df,test_df,gt_df')\n",
    "    \n",
    "    trn_gt_df = construct_gt_df(trn_transactions)\n",
    "    test_gt_df = construct_gt_df(test_transactions)\n",
    "    \n",
    "    trn_df = construct_rerank_df(\n",
    "        trn_gt_df[['customer_id']],past_transactions,\n",
    "        articles,customers,\n",
    "        model_path,\n",
    "        label='label',\n",
    "        gt_df=trn_gt_df,\n",
    "    )\n",
    "    \n",
    "    test_df = construct_rerank_df(\n",
    "        test_gt_df[['customer_id']],past_transactions,\n",
    "        articles,customers,\n",
    "        model_path,\n",
    "        label='label',\n",
    "    )\n",
    "    \n",
    "    print('Evaluate individual score')\n",
    "    pred_df = test_df.groupby('customer_id') \\\n",
    "            .apply(lambda x: x.sort_values(['customer_id','past_purchase_score'],ascending=False)['article_id'].tolist()) \\\n",
    "            .reset_index()\n",
    "    pred_df.columns = ['customer_id','prediction']\n",
    "    past_purchase_score = evaluate_score(pred_df,test_gt_df)\n",
    "    print('Past purchase score: ',past_purchase_score)\n",
    "    \n",
    "    pred_df = test_df.groupby('customer_id') \\\n",
    "            .apply(lambda x: x.sort_values(['customer_id','recent_purchase_score'],ascending=False)['article_id'].tolist()) \\\n",
    "            .reset_index()\n",
    "    pred_df.columns = ['customer_id','prediction']\n",
    "    recent_purchase_score = evaluate_score(pred_df,test_gt_df)\n",
    "    print('Recent purchase score: ',recent_purchase_score)\n",
    "    \n",
    "    print('Fit logistic regression')\n",
    "    clf = LogisticRegression(random_state=1).fit(trn_df[features],trn_df[target])\n",
    "    print(clf.coef_, clf.intercept_)\n",
    "    \n",
    "    print('Evaluate score')\n",
    "    preds = clf.predict_proba(test_df[features])\n",
    "    _,score,_ = feval(preds[:,1],test_df,test_gt_df,k=12)\n",
    "    print('Combined score',score)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433ec944-1fa4-46cd-9d77-a6662e1199ff",
   "metadata": {},
   "source": [
    "****Submission****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a14c6e03-c1fa-46cc-a9a3-e3ee8c5630a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "past_purchase_score recent_purchase_score popular_purchase_2w_score popular_purchase_3w_score\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Construct trn_df\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/24315034/ipykernel_238772/677110032.py:287: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_x[group_name] = test_df[group_name]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit logistic regression\n",
      "[[ 3.92763092e+01  2.63342250e+00 -2.88394032e-03 -2.33594154e-03]] [-7.3545712]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/24315034/ipykernel_238772/677110032.py:287: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_x[group_name] = test_df[group_name]\n",
      "/scratch/local/24315034/ipykernel_238772/677110032.py:287: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_x[group_name] = test_df[group_name]\n",
      "/scratch/local/24315034/ipykernel_238772/677110032.py:287: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_x[group_name] = test_df[group_name]\n",
      "/scratch/local/24315034/ipykernel_238772/677110032.py:287: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_x[group_name] = test_df[group_name]\n",
      "/scratch/local/24315034/ipykernel_238772/677110032.py:287: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_x[group_name] = test_df[group_name]\n",
      "/scratch/local/24315034/ipykernel_238772/677110032.py:287: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_x[group_name] = test_df[group_name]\n",
      "/scratch/local/24315034/ipykernel_238772/677110032.py:287: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_x[group_name] = test_df[group_name]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41min 23s, sys: 6min 20s, total: 47min 43s\n",
      "Wall time: 45min 1s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...</td>\n",
       "      <td>[568601043.0, 783346001.0, 915529003.0, 924243...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000423b00ade91418cceaf3b26c6af3dd342b51fd051e...</td>\n",
       "      <td>[714790020.0, 866731001.0, 372860001.0, 706016...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n",
       "      <td>[794321007.0, 915529005.0, 714790020.0, 783346...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2...</td>\n",
       "      <td>[714790020.0, 573085043.0, 751471001.0, 783346...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00006413d8573cd20ed7128e53b7b13819fe5cfc2d801f...</td>\n",
       "      <td>[866731001.0, 915529003.0, 783346001.0, 924243...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171975</th>\n",
       "      <td>ffffbbf78b6eaac697a8a5dfbfd2bfa8113ee5b403e474...</td>\n",
       "      <td>[557599022.0, 720125039.0, 713997002.0, 791587...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171976</th>\n",
       "      <td>ffffcd5046a6143d29a04fb8c424ce494a76e5cdf4fab5...</td>\n",
       "      <td>[714790020.0, 762846027.0, 866731001.0, 706016...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171977</th>\n",
       "      <td>ffffcf35913a0bee60e8741cb2b4e78b8a98ee5ff2e6a1...</td>\n",
       "      <td>[762846027.0, 794819001.0, 689365050.0, 884081...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171978</th>\n",
       "      <td>ffffd7744cebcf3aca44ae7049d2a94b87074c3d4ffe38...</td>\n",
       "      <td>[714790020.0, 372860002.0, 448509014.0, 788575...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171979</th>\n",
       "      <td>ffffd9ac14e89946416d80e791d064701994755c3ab686...</td>\n",
       "      <td>[714790020.0, 762846027.0, 930380001.0, 924243...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1371980 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              customer_id  \\\n",
       "0       00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...   \n",
       "1       0000423b00ade91418cceaf3b26c6af3dd342b51fd051e...   \n",
       "2       000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...   \n",
       "3       00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2...   \n",
       "4       00006413d8573cd20ed7128e53b7b13819fe5cfc2d801f...   \n",
       "...                                                   ...   \n",
       "171975  ffffbbf78b6eaac697a8a5dfbfd2bfa8113ee5b403e474...   \n",
       "171976  ffffcd5046a6143d29a04fb8c424ce494a76e5cdf4fab5...   \n",
       "171977  ffffcf35913a0bee60e8741cb2b4e78b8a98ee5ff2e6a1...   \n",
       "171978  ffffd7744cebcf3aca44ae7049d2a94b87074c3d4ffe38...   \n",
       "171979  ffffd9ac14e89946416d80e791d064701994755c3ab686...   \n",
       "\n",
       "                                               prediction  \n",
       "0       [568601043.0, 783346001.0, 915529003.0, 924243...  \n",
       "1       [714790020.0, 866731001.0, 372860001.0, 706016...  \n",
       "2       [794321007.0, 915529005.0, 714790020.0, 783346...  \n",
       "3       [714790020.0, 573085043.0, 751471001.0, 783346...  \n",
       "4       [866731001.0, 915529003.0, 783346001.0, 924243...  \n",
       "...                                                   ...  \n",
       "171975  [557599022.0, 720125039.0, 713997002.0, 791587...  \n",
       "171976  [714790020.0, 762846027.0, 866731001.0, 706016...  \n",
       "171977  [762846027.0, 794819001.0, 689365050.0, 884081...  \n",
       "171978  [714790020.0, 372860002.0, 448509014.0, 788575...  \n",
       "171979  [714790020.0, 762846027.0, 930380001.0, 924243...  \n",
       "\n",
       "[1371980 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "features = [\n",
    "    'past_purchase_score',\n",
    "    #'recent_purchase_1w_score',\n",
    "    #'recent_purchase_2w_score',\n",
    "    #'recent_purchase_3w_score',\n",
    "    'recent_purchase_score',\n",
    "    #'popular_purchase_1w_score',\n",
    "    'popular_purchase_2w_score',\n",
    "    'popular_purchase_3w_score',\n",
    "    #'popular_purchase_123w_score',\n",
    "]\n",
    "target = 'label'\n",
    "print(' '.join(features))\n",
    "\n",
    "trn_start_time = '2020-09-15'\n",
    "trn_end_time = '2020-09-22'\n",
    "model_path = 'storage/output/220325_lightgbm_training/220325_dataset_2020-06-01_2020-08-01_2020-09-15_2020-09-22_score:0.0230037_objective:lambdarank_metric:map@12_boosting:dart_seed:0_learning_rate:0.03_num_threads:8_num_iterations:15_early_stopping_round:None.bin'\n",
    "    \n",
    "print('-'*100)\n",
    "\n",
    "trn_start_time = cudf.to_datetime(trn_start_time)\n",
    "trn_end_time = cudf.to_datetime(trn_end_time)\n",
    "\n",
    "past_transactions = transactions[(transactions.t_dat > cudf.to_datetime('2020-01-01')) & (transactions.t_dat <= trn_end_time)]\n",
    "trn_transactions = transactions[(transactions.t_dat > trn_start_time) & (transactions.t_dat <= trn_end_time)]\n",
    "\n",
    "print('Construct trn_df')\n",
    "\n",
    "trn_gt_df = construct_gt_df(trn_transactions)\n",
    "\n",
    "trn_df = construct_rerank_df(\n",
    "    trn_gt_df[['customer_id']],past_transactions,\n",
    "    articles,customers,\n",
    "    model_path,\n",
    "    label='label',\n",
    "    gt_df=trn_gt_df,\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "print('Fit logistic regression')\n",
    "clf = LogisticRegression(random_state=1).fit(trn_df[features],trn_df[target])\n",
    "print(clf.coef_, clf.intercept_)\n",
    "\n",
    "sub_df_reader = pd.read_csv('storage/sample_submission.csv',chunksize=int(2e5))\n",
    "final_sub_df = None\n",
    "for sub_df in sub_df_reader:\n",
    "    test_df = construct_rerank_df(\n",
    "        sub_df,past_transactions,\n",
    "        articles,customers,\n",
    "        model_path,\n",
    "        label='label',\n",
    "    )\n",
    "    preds = clf.predict_proba(test_df[features])\n",
    "    sub_df = construct_sub_df(test_df,preds[:,1],k=12)\n",
    "    if final_sub_df is None:\n",
    "        final_sub_df = sub_df\n",
    "    else:\n",
    "        final_sub_df = pd.concat([final_sub_df,sub_df])\n",
    "final_sub_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02780a07-3bf5-43da-9692-34beac1fb180",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_sub_df.to_csv('submission_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4509e1ce-ee03-4800-b6d7-f00d350b078a",
   "metadata": {},
   "source": [
    "****Reranking with LightGBM****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "eeda2199-3a51-4352-a448-040407d5a3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_y_group(data,features,target,only_x=False,verbose=False):\n",
    "    data = data.sort_values('customer_id').reset_index()\n",
    "    group = data.groupby('customer_id').size().to_frame('size')['size']\n",
    "    return data[features],data[target],group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "edeffc11-6446-4ee0-95d0-52eb1f6562b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_x,trn_y,trn_grp = x_y_group(trn_df,features,target)\n",
    "trn_dataset = lgb.Dataset(trn_x,label=trn_y,group=trn_grp)\n",
    "\n",
    "test_dataset = lgb.Dataset(test_df[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "30a702a5-c51d-4b54-80d0-d86953f36b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032674 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 259\n",
      "[LightGBM] [Info] Number of data points in the train set: 7835273, number of used features: 2\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's MAP@12: 0.0206276\n",
      "CPU times: user 15.8 s, sys: 339 ms, total: 16.2 s\n",
      "Wall time: 14.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "param = dict(\n",
    "    objective='lambdarank',\n",
    "    metric='map@12',\n",
    "    boosting='dart',\n",
    "    num_round = 1,\n",
    "    seed=0,\n",
    "    learning_rate=0.1,\n",
    "    num_threads=8,\n",
    ")\n",
    "bst = lgb.train(\n",
    "    param,\n",
    "    trn_dataset,\n",
    "    feval=feval,\n",
    "    valid_sets=[test_dataset],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42faadd7-5053-42f5-b03b-99ddb3ec178e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAPIDSai-21.10",
   "language": "python",
   "name": "rapidsai-21.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
